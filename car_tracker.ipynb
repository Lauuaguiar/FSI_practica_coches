{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6680805",
   "metadata": {},
   "source": [
    "Implementación del Sistema de Detección y Conteo de Vehículos\n",
    "Para la realización de este trabajo se ha utilizado exclusivamente la librería OpenCV (cv2) junto con numpy para el manejo de matrices y operaciones matemáticas. El objetivo del código es procesar un flujo de video de tráfico, detectar vehículos en movimiento, realizar un seguimiento (tracking) de los mismos y contarlos según crucen líneas virtuales predefinidas en diferentes carriles y direcciones.\n",
    "\n",
    "1. Preprocesamiento y Funciones Auxiliares\n",
    "El primer paso fundamental es el acondicionamiento de la imagen. Dado que el video original puede tener una resolución elevada (1920x1080), se define la función rescale para redimensionar cada frame a una escala más manejable (0.6x). Esto no solo facilita la visualización en pantalla, sino que reduce significativamente la carga computacional, permitiendo un procesamiento más fluido en tiempo real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42071956",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale(frame, scale=0.6):\n",
    "    \"\"\"Escala un frame a un tamaño más manejable.\"\"\"\n",
    "    w = int(frame.shape[1] * scale)\n",
    "    h = int(frame.shape[0] * scale)\n",
    "    return cv2.resize(frame, (w, h), interpolation=cv2.INTER_AREA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cd3fe0",
   "metadata": {},
   "source": [
    "Adicionalmente, se implementan funciones geométricas clave para la lógica de conteo: point_line_signed_distance y point_to_segment_proj_dist. Estas funciones permiten calcular la posición relativa de un punto (centroide del vehículo) respecto a un segmento de línea, determinando si ha ocurrido un cruce y la distancia exacta al segmento, lo cual es vital para evitar falsos positivos.\n",
    "\n",
    "2. Detección de Movimiento y Sustracción de Fondo\n",
    "El núcleo del sistema de detección recae en el algoritmo de sustracción de fondo MOG2 (createBackgroundSubtractorMOG2). Este método modela cada píxel como una mezcla de gaussianas, lo que le permite adaptarse a cambios de iluminación graduales y separar los objetos en movimiento del fondo estático."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5371b235",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_detector = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=40, detectShadows=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ad5f98",
   "metadata": {},
   "source": [
    "Se establece un periodo de calibración inicial de 60 frames donde el sistema procesa el video sin realizar conteo. Esto permite que el modelo de fondo se estabilice y aprenda la escena estática, evitando detecciones erróneas al inicio de la ejecución.\n",
    "\n",
    "3. Procesamiento Morfológico y Limpieza de Máscara\n",
    "La máscara binaria obtenida del detector MOG2 suele contener ruido (movimiento de árboles, reflejos) y fragmentación (vehículos divididos en partes). Para solucionar esto, se aplica una cadena de procesamiento de imagen robusta:\n",
    "\n",
    "Suavizado Gaussiano (GaussianBlur): Se aplica al frame en escala de grises antes de la detección para reducir el ruido de alta frecuencia del asfalto.\n",
    "\n",
    "Umbralizado (threshold): Se aplica un corte estricto (250) a la máscara resultante para eliminar sombras grises (detectShadows=True las marca en gris), dejando solo los píxeles blancos correspondientes a objetos sólidos.\n",
    "\n",
    "Operaciones Morfológicas:\n",
    "\n",
    "Erosión (erode): Con un kernel de 3x3, se eliminan pequeños píxeles de ruido aislados.\n",
    "\n",
    "Dilatación (dilate): Con un kernel de 5x5, se expanden las regiones blancas restantes para recuperar el volumen del vehículo.\n",
    "\n",
    "Cierre (morphologyEx con MORPH_CLOSE): Con un kernel de 11x11, se fusionan componentes cercanos. Esto es crítico para detectar camiones o vehículos largos como un único objeto en lugar de múltiples fragmentos (cabina + remolque)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c22058e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, image_bin = cv2.threshold(image_mask, 250, 255, cv2.THRESH_BINARY)\n",
    "image_bin = cv2.erode(image_bin, kernel_erode, iterations=1)\n",
    "image_bin = cv2.dilate(image_bin, kernel_dilate, iterations=2)\n",
    "image_bin = cv2.morphologyEx(image_bin, cv2.MORPH_CLOSE, kernel_close)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910a38e3",
   "metadata": {},
   "source": [
    "4. Detección de Contornos y Filtrado\n",
    "Sobre la máscara binaria limpia, se utiliza cv2.findContours para identificar los objetos. Se aplica un filtrado riguroso basado en el área (MIN_AREA_BLOB = 250), dimensiones mínimas (MIN_W, MIN_H) y relación de aspecto (MIN_ASPECT_RATIO, MAX_ASPECT_RATIO). Además, se introduce un filtro de horizonte (if y < 150: continue), descartando cualquier movimiento en la parte superior de la imagen (cielo o vegetación lejana) que no corresponda a la carretera.\n",
    "\n",
    "5. Seguimiento (Tracking) y Lógica de Conteo\n",
    "El sistema implementa un algoritmo de seguimiento basado en la distancia Euclidiana entre centroides. Para cada frame, se comparan los centroides detectados con los objetos ya registrados en tracking_objects. Si la distancia es menor a MAX_DISTANCE, se actualiza la posición del objeto existente; de lo contrario, se registra como un nuevo vehículo con un ID único.\n",
    "\n",
    "El conteo se realiza mediante líneas virtuales definidas por coordenadas (P1, P2). Se evalúa si la trayectoria de un vehículo cruza estas líneas analizando el cambio de signo en la distancia con signo (point_line_signed_distance) entre su posición anterior y la actual.\n",
    "\n",
    "Se han definido 5 líneas de conteo estratégicas para cubrir diferentes flujos de tráfico:\n",
    "\n",
    "V1 y V2: Tráfico principal Norte y Sur.\n",
    "\n",
    "V3 y V4: Incorporaciones laterales.\n",
    "\n",
    "V5: Carril de desaceleración.\n",
    "\n",
    "Cada vehículo cuenta con un registro de banderas (direction_counted) para asegurar que solo sea contabilizado una vez por cada línea que cruce, garantizando la precisión del sistema \"Total\" y de los contadores individuales por vía.\n",
    "\n",
    "6. Visualización de Resultados\n",
    "Finalmente, el sistema genera una visualización en tiempo real compuesta por tres capas de información:\n",
    "\n",
    "Video Original: Referencia visual.\n",
    "\n",
    "Máscara Procesada: Visualización de la \"visión\" interna del algoritmo, útil para depuración.\n",
    "\n",
    "Monitor Final: Overlay con las cajas delimitadoras (bounding boxes) de los vehículos, sus IDs, las líneas de conteo y un panel de estadísticas actualizado frame a frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd105483",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "VIDEO_PATH = 'trafico.mp4'\n",
    "SCALE = 0.6\n",
    "MIN_AREA, MAX_DIST = 100, 80\n",
    "PX_TO_METERS = 0.15 \n",
    "\n",
    "KERNEL_ERODE = np.ones((3, 3), np.uint8)\n",
    "KERNEL_DILATE = np.ones((5, 5), np.uint8)\n",
    "KERNEL_CLOSE = np.ones((11, 11), np.uint8)\n",
    "\n",
    "LINES_CFG = [\n",
    "    {\"id\": \"north\", \"label\": \"NORTE (P)\", \"pts\": ((550, 450), (650, 400)), \"col\": (255, 0, 0),   \"th\": 25, \"tol\": (0, 1)},\n",
    "    {\"id\": \"south\", \"label\": \"SUR (P)\",   \"pts\": ((750, 425), (850, 375)), \"col\": (0, 0, 255),   \"th\": 25, \"tol\": (0, 1)},\n",
    "    {\"id\": \"inc_n\", \"label\": \"INC NORTE\", \"pts\": ((300, 550), (450, 500)), \"col\": (255, 255, 0), \"th\": 40, \"tol\": (0, 1)},\n",
    "    {\"id\": \"inc_s\", \"label\": \"INC SUR\",   \"pts\": ((880, 290), (940, 250)), \"col\": (0, 255, 255), \"th\": 25, \"tol\": (0, 1)},\n",
    "    {\"id\": \"decel\", \"label\": \"DECEL\",     \"pts\": ((150, 200), (120, 165)),  \"col\": (255, 0, 255), \"th\": 60, \"tol\": (-0.2, 1.2)} \n",
    "]\n",
    "\n",
    "def get_crossing_info(pt, a, b):\n",
    "    v_line = np.array(b) - np.array(a)\n",
    "    v_pt = np.array(pt) - np.array(a)\n",
    "    line_len_sq = v_line.dot(v_line)\n",
    "    if line_len_sq == 0: return np.linalg.norm(v_pt), 0, 0\n",
    "    t = v_pt.dot(v_line) / line_len_sq\n",
    "    dist = np.linalg.norm(np.array(pt) - (np.array(a) + t * v_line))\n",
    "    sign = (b[0]-a[0])*(pt[1]-a[1]) - (b[1]-a[1])*(pt[0]-a[0])\n",
    "    return dist, t, sign\n",
    "\n",
    "def rescale(frame, scale=SCALE):\n",
    "    return cv2.resize(frame, (int(frame.shape[1]*scale), int(frame.shape[0]*scale)), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "def estimate_speed(hist, lookback=6):\n",
    "    \"\"\"Calcula km/h basándose en la distancia recorrida en los últimos 'lookback' frames.\"\"\"\n",
    "    if len(hist) < lookback: return 0.0\n",
    "    p1, t1 = hist[-lookback][:2], hist[-lookback][2]\n",
    "    p2, t2 = hist[-1][:2], hist[-1][2]\n",
    "    dist_px = np.hypot(p2[0]-p1[0], p2[1]-p1[1])\n",
    "    dist_m = dist_px * PX_TO_METERS\n",
    "    time_s = (t2 - t1) / 1000.0\n",
    "    if time_s <= 0: return 0.0\n",
    "    speed_ms = dist_m / time_s\n",
    "    return speed_ms * 3.6\n",
    "\n",
    "cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "bg_subtractor = cv2.createBackgroundSubtractorMOG2(history=250, varThreshold=32, detectShadows=True)\n",
    "\n",
    "# Estabilización inicial\n",
    "for _ in range(150):\n",
    "    ret, fr = cap.read()\n",
    "    if ret: bg_subtractor.apply(cv2.cvtColor(rescale(fr), cv2.COLOR_BGR2GRAY))\n",
    "\n",
    "# Estado Global\n",
    "tracking_objs = {} \n",
    "counts = {cfg[\"id\"]: 0 for cfg in LINES_CFG}\n",
    "counts[\"total\"] = 0\n",
    "counted_ids = {cfg[\"id\"]: set() for cfg in LINES_CFG} \n",
    "next_id = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret: break\n",
    "    \n",
    "    frame = rescale(frame)\n",
    "    curr_t = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
    "    \n",
    "    # 1. Procesamiento de Imagen\n",
    "    mask = bg_subtractor.apply(cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY), learningRate=0.003)\n",
    "    mask[mask == 127] = 0 \n",
    "    mask = cv2.medianBlur(mask, 5)\n",
    "    \n",
    "    # --- VISUALIZACIÓN 1: Máscara Cruda ---\n",
    "    cv2.imshow(\"1. Mascara Cruda (BgSub)\", mask)\n",
    "\n",
    "    _, bin_img = cv2.threshold(mask, 200, 255, cv2.THRESH_BINARY)\n",
    "    bin_img = cv2.morphologyEx(bin_img, cv2.MORPH_OPEN, KERNEL_ERODE)\n",
    "    bin_img = cv2.morphologyEx(bin_img, cv2.MORPH_CLOSE, KERNEL_CLOSE)\n",
    "    \n",
    "    # --- VISUALIZACIÓN 2: Binaria Final ---\n",
    "    cv2.imshow(\"2. Imagen Binarizada (Final)\", bin_img)\n",
    "\n",
    "    # 2. Tracking\n",
    "    contours, _ = cv2.findContours(bin_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    curr_objs = {}\n",
    "    \n",
    "    for cnt in contours:\n",
    "        if cv2.contourArea(cnt) < MIN_AREA: continue\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        if w < 10 or h < 10 or not (0.2 < w/h < 5.0): continue\n",
    "        \n",
    "        cx, cy = x + w//2, y + h//2\n",
    "        \n",
    "        c_id, min_d = -1, MAX_DIST\n",
    "        for tid, (tx, ty, thist) in tracking_objs.items():\n",
    "            d = np.hypot(cx - tx, cy - ty)\n",
    "            if d < min_d: min_d, c_id = d, tid\n",
    "            \n",
    "        if c_id == -1: c_id, next_id = next_id, next_id + 1\n",
    "        \n",
    "        hist = tracking_objs[c_id][2] if c_id in tracking_objs else []\n",
    "        hist.append((cx, cy, curr_t))\n",
    "        if len(hist) > 20: hist = hist[-20:]\n",
    "        curr_objs[c_id] = (cx, cy, hist)\n",
    "\n",
    "        # Cálculo de velocidad\n",
    "        kmh = estimate_speed(hist)\n",
    "\n",
    "        # Lógica de Cruce\n",
    "        if len(hist) >= 2:\n",
    "            prev_pt, curr_pt = hist[-2][:2], hist[-1][:2]\n",
    "            for line in LINES_CFG:\n",
    "                lid = line[\"id\"]\n",
    "                if c_id in counted_ids[lid]: continue\n",
    "                dist, t, sign_curr = get_crossing_info(curr_pt, line[\"pts\"][0], line[\"pts\"][1])\n",
    "                _, _, sign_prev = get_crossing_info(prev_pt, line[\"pts\"][0], line[\"pts\"][1])\n",
    "                \n",
    "                if (sign_curr * sign_prev < 0) and (dist < line[\"th\"]) and (line[\"tol\"][0] <= t <= line[\"tol\"][1]):\n",
    "                    counts[lid] += 1\n",
    "                    counts[\"total\"] += 1\n",
    "                    counted_ids[lid].add(c_id)\n",
    "\n",
    "        # Dibujar\n",
    "        is_counted = any(c_id in s for s in counted_ids.values())\n",
    "        col = (0, 255, 0) if is_counted else (0, 255, 255)\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), col, 2)\n",
    "        label = f\"ID:{c_id} {int(kmh)}km/h\"\n",
    "        cv2.putText(frame, label, (x, y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, col, 1)\n",
    "\n",
    "    tracking_objs = curr_objs\n",
    "\n",
    "    # 3. Panel Informativo\n",
    "    overlay = frame.copy()\n",
    "    cv2.rectangle(overlay, (10, 10), (320, 60 + len(LINES_CFG)*30), (0, 0, 0), -1)\n",
    "    frame = cv2.addWeighted(overlay, 0.4, frame, 0.6, 0)\n",
    "    \n",
    "    cv2.putText(frame, f\"TOTAL: {counts['total']}\", (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "    for i, line in enumerate(LINES_CFG):\n",
    "        cv2.line(frame, line[\"pts\"][0], line[\"pts\"][1], line[\"col\"], 2)\n",
    "        txt = f\"{line['label']}: {counts[line['id']]}\"\n",
    "        cv2.putText(frame, txt, (20, 80 + i*30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, line[\"col\"], 2)\n",
    "\n",
    "    cv2.imshow(\"3. Traffic Monitor\", frame)\n",
    "    if cv2.waitKey(15) & 0xFF == ord('d'): break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e19fa9",
   "metadata": {},
   "source": [
    "### Código para el segundo vídeo de prueba con la misma estructura y esqueleto pero parámetros cambiados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14dffd1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibrando...\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "def rescale(frame, scale=0.8): \n",
    "    w = int(frame.shape[1] * scale)\n",
    "    h = int(frame.shape[0] * scale)\n",
    "    return cv2.resize(frame, (w, h), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "def point_line_signed_distance(pt, a, b):\n",
    "    return (b[0]-a[0])*(pt[1]-a[1]) - (b[1]-a[1])*(pt[0]-a[0])\n",
    "\n",
    "def point_to_segment_proj_dist(pt, a, b):\n",
    "    pax = pt[0] - a[0]; pay = pt[1] - a[1]\n",
    "    bax = b[0] - a[0]; bay = b[1] - a[1]\n",
    "    denom = bax*bax + bay*bay\n",
    "    if denom == 0: return np.hypot(pax, pay), 0.0\n",
    "    t = (pax*bax + pay*bay) / denom\n",
    "    if t < 0.0: projx, projy = a\n",
    "    elif t > 1.0: projx, projy = b\n",
    "    else: projx, projy = a[0] + t * bax, a[1] + t * bay\n",
    "    return np.hypot(pt[0]-projx, pt[1]-projy), t\n",
    "\n",
    "cap = cv2.VideoCapture('trafico_2.mp4')\n",
    "FPS = cap.get(cv2.CAP_PROP_FPS) or 25\n",
    "\n",
    "object_detector = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=25, detectShadows=True)\n",
    "\n",
    "tracking_objects = {} \n",
    "car_ids_counted = set()\n",
    "vehicle_counts = {\"Total\": 0}\n",
    "left_road_count = 0; right_road_count = 0  \n",
    "direction_counted = defaultdict(set)\n",
    "next_car_id = 0\n",
    "\n",
    "MIN_AREA_BLOB = 250    \n",
    "MAX_DISTANCE = 150     \n",
    "MAX_DISAPPEARED = 10   \n",
    "\n",
    "kernel_close = np.ones((9, 9), np.uint8)  \n",
    "kernel_open = np.ones((3, 3), np.uint8)   \n",
    "kernel_dilate = np.ones((3, 3), np.uint8) \n",
    "\n",
    "PX_TO_KMH_FACTOR = 2.6\n",
    "LINE_V1_P1 = (20, 420); LINE_V1_P2 = (450, 420)\n",
    "LINE_V2_P1 = (600, 420); LINE_V2_P2 = (1050, 420)\n",
    "LINE_DIST_THRESH = 40\n",
    "\n",
    "print(\"Calibrando...\")\n",
    "for _ in range(40):\n",
    "    ret, frame = cap.read()\n",
    "    if not ret: break\n",
    "    frame_s = rescale(frame)\n",
    "    gray = cv2.cvtColor(frame_s, cv2.COLOR_BGR2GRAY)\n",
    "    gray_blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    object_detector.apply(gray_blur)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret: break\n",
    "\n",
    "    frame_s = rescale(frame)\n",
    "    current_time = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
    "    \n",
    "    cv2.imshow(\"1. Video Original\", frame_s)\n",
    "\n",
    "    gray = cv2.cvtColor(frame_s, cv2.COLOR_BGR2GRAY)\n",
    "    gray_blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "    image_mask_raw = object_detector.apply(gray_blur, learningRate=0.001)\n",
    "    \n",
    "    _, image_bin = cv2.threshold(image_mask_raw, 200, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    image_bin = cv2.morphologyEx(image_bin, cv2.MORPH_CLOSE, kernel_close) \n",
    "    image_bin = cv2.morphologyEx(image_bin, cv2.MORPH_OPEN, kernel_open)\n",
    "    image_bin = cv2.dilate(image_bin, kernel_dilate, iterations=1)         \n",
    "    \n",
    "    cv2.imshow(\"2. Mascara Procesada\", image_bin)\n",
    "\n",
    "    contours, _ = cv2.findContours(image_bin, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    img_final = frame_s.copy()\n",
    "    detections = []\n",
    "\n",
    "    cv2.line(img_final, LINE_V1_P1, LINE_V1_P2, (255, 0, 0), 2)\n",
    "    cv2.line(img_final, LINE_V2_P1, LINE_V2_P2, (0, 0, 255), 2)\n",
    "\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if area < MIN_AREA_BLOB: continue\n",
    "        \n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        \n",
    "        if y < 220: continue \n",
    "        \n",
    "        cx, cy = x + w//2, y + h//2\n",
    "        detections.append((cx, cy, x, y, w, h))\n",
    "\n",
    "    if len(tracking_objects) == 0:\n",
    "        for det in detections:\n",
    "            cx, cy, x, y, w, h = det\n",
    "            tracking_objects[next_car_id] = {'center':(cx,cy), 'history':[(cx,cy)], 'disappeared':0, 'box':(x,y,w,h)}\n",
    "            next_car_id += 1\n",
    "    else:\n",
    "        object_ids = list(tracking_objects.keys())\n",
    "        current_centroids = [tracking_objects[obj_id]['center'] for obj_id in object_ids]\n",
    "        \n",
    "        used_rows = set(); used_cols = set()\n",
    "        if len(detections) > 0:\n",
    "            D = np.zeros((len(current_centroids), len(detections)))\n",
    "            for i in range(len(current_centroids)):\n",
    "                for j in range(len(detections)):\n",
    "                    D[i, j] = np.hypot(current_centroids[i][0]-detections[j][0], current_centroids[i][1]-detections[j][1])\n",
    "\n",
    "            rows = D.min(axis=1).argsort(); cols = D.argmin(axis=1)[rows]\n",
    "\n",
    "            for (row, col) in zip(rows, cols):\n",
    "                if row in used_rows or col in used_cols: continue\n",
    "                if D[row, col] > MAX_DISTANCE: continue\n",
    "\n",
    "                obj_id = object_ids[row]\n",
    "                cx, cy, x, y, w, h = detections[col]\n",
    "                \n",
    "                tracking_objects[obj_id]['center'] = (cx, cy)\n",
    "                tracking_objects[obj_id]['box'] = (x, y, w, h)\n",
    "                tracking_objects[obj_id]['disappeared'] = 0\n",
    "                tracking_objects[obj_id]['history'].append((cx, cy))\n",
    "                if len(tracking_objects[obj_id]['history']) > 20: tracking_objects[obj_id]['history'].pop(0)\n",
    "\n",
    "                used_rows.add(row); used_cols.add(col)\n",
    "\n",
    "        for row in range(len(object_ids)):\n",
    "            if row not in used_rows: tracking_objects[object_ids[row]]['disappeared'] += 1\n",
    "        for col in range(len(detections)):\n",
    "            if col not in used_cols:\n",
    "                cx, cy, x, y, w, h = detections[col]\n",
    "                tracking_objects[next_car_id] = {'center':(cx,cy), 'history':[(cx,cy)], 'disappeared':0, 'box':(x,y,w,h)}\n",
    "                next_car_id += 1\n",
    "\n",
    "    tracking_objects = {k: v for k, v in tracking_objects.items() if v['disappeared'] <= MAX_DISAPPEARED}\n",
    "\n",
    "    for car_id, data in tracking_objects.items():\n",
    "        if data['disappeared'] > 0: continue\n",
    "        cx, cy = data['center']; x, y, w, h = data['box']; hist = data['history']\n",
    "\n",
    "        def count_vehicle(direction_key, ref_counter):\n",
    "            if direction_key not in direction_counted[car_id]:\n",
    "                direction_counted[car_id].add(direction_key)\n",
    "                if car_id not in car_ids_counted:\n",
    "                    vehicle_counts[\"Total\"] += 1\n",
    "                    car_ids_counted.add(car_id)\n",
    "                return True\n",
    "            return False\n",
    "\n",
    "        if len(hist) >= 3:\n",
    "            (cx_prev, cy_prev) = hist[-3]\n",
    "            (cx_curr, cy_curr) = hist[-1]\n",
    "            if (point_line_signed_distance((cx_prev, cy_prev), LINE_V1_P1, LINE_V1_P2) * point_line_signed_distance((cx_curr, cy_curr), LINE_V1_P1, LINE_V1_P2) < 0):\n",
    "                d, t = point_to_segment_proj_dist((cx_curr, cy_curr), LINE_V1_P1, LINE_V1_P2)\n",
    "                if d < LINE_DIST_THRESH and 0 <= t <= 1: \n",
    "                    if count_vehicle(\"left_road\", left_road_count): left_road_count += 1\n",
    "            if (point_line_signed_distance((cx_prev, cy_prev), LINE_V2_P1, LINE_V2_P2) * point_line_signed_distance((cx_curr, cy_curr), LINE_V2_P1, LINE_V2_P2) < 0):\n",
    "                d, t = point_to_segment_proj_dist((cx_curr, cy_curr), LINE_V2_P1, LINE_V2_P2)\n",
    "                if d < LINE_DIST_THRESH and 0 <= t <= 1: \n",
    "                    if count_vehicle(\"right_road\", right_road_count): right_road_count += 1\n",
    "\n",
    "        color = (0, 255, 0) if car_id in car_ids_counted else (0, 255, 255)\n",
    "        cv2.rectangle(img_final, (x, y), (x+w, y+h), color, 2)\n",
    "        cv2.putText(img_final, f\"ID:{car_id}\", (x, y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "\n",
    "    # Interfaz\n",
    "    overlay = img_final.copy()\n",
    "    cv2.rectangle(overlay, (0,0), (300,120), (0,0,0), -1)\n",
    "    img_final = cv2.addWeighted(overlay, 0.6, img_final, 0.4, 0)\n",
    "    cv2.putText(img_final, f\"TOTAL: {vehicle_counts['Total']}\", (10,35), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,255,0), 2)\n",
    "    cv2.putText(img_final, f\"Ida: {left_road_count}\", (10,70), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,200,200), 1)\n",
    "    cv2.putText(img_final, f\"Vuelta: {right_road_count}\", (10,100), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (200,200,255), 1)\n",
    "\n",
    "    cv2.imshow(\"3. Monitor de Trafico (Final)\", img_final)\n",
    "\n",
    "    if cv2.waitKey(15) & 0xFF == ord('d'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
