{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6680805",
   "metadata": {},
   "source": [
    "Implementación del Sistema de Detección y Conteo de Vehículos\n",
    "Para la realización de este trabajo se ha utilizado exclusivamente la librería OpenCV (cv2) junto con numpy para el manejo de matrices y operaciones matemáticas. El objetivo del código es procesar un flujo de video de tráfico, detectar vehículos en movimiento, realizar un seguimiento (tracking) de los mismos y contarlos según crucen líneas virtuales predefinidas en diferentes carriles y direcciones.\n",
    "\n",
    "1. Preprocesamiento y Funciones Auxiliares\n",
    "El primer paso fundamental es el acondicionamiento de la imagen. Dado que el video original puede tener una resolución elevada (1920x1080), se define la función rescale para redimensionar cada frame a una escala más manejable (0.6x). Esto no solo facilita la visualización en pantalla, sino que reduce significativamente la carga computacional, permitiendo un procesamiento más fluido en tiempo real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42071956",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale(frame, scale=0.6):\n",
    "    \"\"\"Escala un frame a un tamaño más manejable.\"\"\"\n",
    "    w = int(frame.shape[1] * scale)\n",
    "    h = int(frame.shape[0] * scale)\n",
    "    return cv2.resize(frame, (w, h), interpolation=cv2.INTER_AREA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cd3fe0",
   "metadata": {},
   "source": [
    "Adicionalmente, se implementan funciones geométricas clave para la lógica de conteo: point_line_signed_distance y point_to_segment_proj_dist. Estas funciones permiten calcular la posición relativa de un punto (centroide del vehículo) respecto a un segmento de línea, determinando si ha ocurrido un cruce y la distancia exacta al segmento, lo cual es vital para evitar falsos positivos.\n",
    "\n",
    "2. Detección de Movimiento y Sustracción de Fondo\n",
    "El núcleo del sistema de detección recae en el algoritmo de sustracción de fondo MOG2 (createBackgroundSubtractorMOG2). Este método modela cada píxel como una mezcla de gaussianas, lo que le permite adaptarse a cambios de iluminación graduales y separar los objetos en movimiento del fondo estático."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5371b235",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_detector = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=40, detectShadows=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ad5f98",
   "metadata": {},
   "source": [
    "Se establece un periodo de calibración inicial de 60 frames donde el sistema procesa el video sin realizar conteo. Esto permite que el modelo de fondo se estabilice y aprenda la escena estática, evitando detecciones erróneas al inicio de la ejecución.\n",
    "\n",
    "3. Procesamiento Morfológico y Limpieza de Máscara\n",
    "La máscara binaria obtenida del detector MOG2 suele contener ruido (movimiento de árboles, reflejos) y fragmentación (vehículos divididos en partes). Para solucionar esto, se aplica una cadena de procesamiento de imagen robusta:\n",
    "\n",
    "Suavizado Gaussiano (GaussianBlur): Se aplica al frame en escala de grises antes de la detección para reducir el ruido de alta frecuencia del asfalto.\n",
    "\n",
    "Umbralizado (threshold): Se aplica un corte estricto (250) a la máscara resultante para eliminar sombras grises (detectShadows=True las marca en gris), dejando solo los píxeles blancos correspondientes a objetos sólidos.\n",
    "\n",
    "Operaciones Morfológicas:\n",
    "\n",
    "Erosión (erode): Con un kernel de 3x3, se eliminan pequeños píxeles de ruido aislados.\n",
    "\n",
    "Dilatación (dilate): Con un kernel de 5x5, se expanden las regiones blancas restantes para recuperar el volumen del vehículo.\n",
    "\n",
    "Cierre (morphologyEx con MORPH_CLOSE): Con un kernel de 11x11, se fusionan componentes cercanos. Esto es crítico para detectar camiones o vehículos largos como un único objeto en lugar de múltiples fragmentos (cabina + remolque)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c22058e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, image_bin = cv2.threshold(image_mask, 250, 255, cv2.THRESH_BINARY)\n",
    "image_bin = cv2.erode(image_bin, kernel_erode, iterations=1)\n",
    "image_bin = cv2.dilate(image_bin, kernel_dilate, iterations=2)\n",
    "image_bin = cv2.morphologyEx(image_bin, cv2.MORPH_CLOSE, kernel_close)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910a38e3",
   "metadata": {},
   "source": [
    "4. Detección de Contornos y Filtrado\n",
    "Sobre la máscara binaria limpia, se utiliza cv2.findContours para identificar los objetos. Se aplica un filtrado riguroso basado en el área (MIN_AREA_BLOB = 250), dimensiones mínimas (MIN_W, MIN_H) y relación de aspecto (MIN_ASPECT_RATIO, MAX_ASPECT_RATIO). Además, se introduce un filtro de horizonte (if y < 150: continue), descartando cualquier movimiento en la parte superior de la imagen (cielo o vegetación lejana) que no corresponda a la carretera.\n",
    "\n",
    "5. Seguimiento (Tracking) y Lógica de Conteo\n",
    "El sistema implementa un algoritmo de seguimiento basado en la distancia Euclidiana entre centroides. Para cada frame, se comparan los centroides detectados con los objetos ya registrados en tracking_objects. Si la distancia es menor a MAX_DISTANCE, se actualiza la posición del objeto existente; de lo contrario, se registra como un nuevo vehículo con un ID único.\n",
    "\n",
    "El conteo se realiza mediante líneas virtuales definidas por coordenadas (P1, P2). Se evalúa si la trayectoria de un vehículo cruza estas líneas analizando el cambio de signo en la distancia con signo (point_line_signed_distance) entre su posición anterior y la actual.\n",
    "\n",
    "Se han definido 5 líneas de conteo estratégicas para cubrir diferentes flujos de tráfico:\n",
    "\n",
    "V1 y V2: Tráfico principal Norte y Sur.\n",
    "\n",
    "V3 y V4: Incorporaciones laterales.\n",
    "\n",
    "V5: Carril de desaceleración.\n",
    "\n",
    "Cada vehículo cuenta con un registro de banderas (direction_counted) para asegurar que solo sea contabilizado una vez por cada línea que cruce, garantizando la precisión del sistema \"Total\" y de los contadores individuales por vía.\n",
    "\n",
    "6. Visualización de Resultados\n",
    "Finalmente, el sistema genera una visualización en tiempo real compuesta por tres capas de información:\n",
    "\n",
    "Video Original: Referencia visual.\n",
    "\n",
    "Máscara Procesada: Visualización de la \"visión\" interna del algoritmo, útil para depuración.\n",
    "\n",
    "Monitor Final: Overlay con las cajas delimitadoras (bounding boxes) de los vehículos, sus IDs, las líneas de conteo y un panel de estadísticas actualizado frame a frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cd105483",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "VIDEO_PATH = 'trafico.mp4'\n",
    "SCALE = 0.6\n",
    "MIN_AREA, MAX_DIST = 100, 80\n",
    "PX_TO_METERS = 0.15 \n",
    "\n",
    "KERNEL_ERODE = np.ones((3, 3), np.uint8)\n",
    "KERNEL_CLOSE = np.ones((11, 11), np.uint8)  # Atención: 11x11 puede borrar blobs pequeños\n",
    "\n",
    "LINES_CFG = [\n",
    "    {\"id\": \"north\", \"label\": \"NORTE (P)\", \"pts\": ((550, 450), (650, 400)), \"col\": (255, 0, 0),   \"th\": 25, \"tol\": (0, 1)},\n",
    "    {\"id\": \"south\", \"label\": \"SUR (P)\",   \"pts\": ((750, 425), (850, 375)), \"col\": (0, 0, 255),   \"th\": 25, \"tol\": (0, 1)},\n",
    "    {\"id\": \"inc_n\", \"label\": \"INC NORTE\", \"pts\": ((300, 550), (450, 500)), \"col\": (255, 255, 0), \"th\": 40, \"tol\": (0, 1)},\n",
    "    {\"id\": \"inc_s\", \"label\": \"INC SUR\",   \"pts\": ((880, 290), (940, 250)), \"col\": (0, 255, 255), \"th\": 25, \"tol\": (0, 1)},\n",
    "    {\"id\": \"decel\", \"label\": \"DECEL\",     \"pts\": ((110, 200), (90, 170)),  \"col\": (255, 0, 255), \"th\": 60, \"tol\": (-0.2, 1.2)} \n",
    "]\n",
    "\n",
    "def get_crossing_info(pt, a, b):\n",
    "    v_line = np.array(b) - np.array(a)\n",
    "    v_pt = np.array(pt) - np.array(a)\n",
    "    line_len_sq = v_line.dot(v_line)\n",
    "    if line_len_sq == 0: return np.linalg.norm(v_pt), 0, 0\n",
    "    t = v_pt.dot(v_line) / line_len_sq\n",
    "    dist = np.linalg.norm(np.array(pt) - (np.array(a) + t * v_line))\n",
    "    sign = (b[0]-a[0])*(pt[1]-a[1]) - (b[1]-a[1])*(pt[0]-a[0])\n",
    "    return dist, t, sign\n",
    "\n",
    "def rescale(frame, scale=SCALE):\n",
    "    return cv2.resize(frame, (int(frame.shape[1]*scale), int(frame.shape[0]*scale)), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "def estimate_speed(hist, lookback=6):\n",
    "    if len(hist) < lookback: return 0.0\n",
    "    p1, t1 = hist[-lookback][:2], hist[-lookback][2]\n",
    "    p2, t2 = hist[-1][:2], hist[-1][2]\n",
    "    dist_px = np.hypot(p2[0]-p1[0], p2[1]-p1[1])\n",
    "    dist_m = dist_px * PX_TO_METERS\n",
    "    time_s = (t2 - t1) / 1000.0\n",
    "    if time_s <= 0: return 0.0\n",
    "    speed_ms = dist_m / time_s\n",
    "    return speed_ms * 3.6\n",
    "\n",
    "cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "bg_subtractor = cv2.createBackgroundSubtractorMOG2(history=400, varThreshold=12, detectShadows=True)\n",
    "\n",
    "# Estabilización inicial (calentamiento del sustractor)\n",
    "for _ in range(150):\n",
    "    ret, fr = cap.read()\n",
    "    if ret: bg_subtractor.apply(cv2.cvtColor(rescale(fr), cv2.COLOR_BGR2GRAY))\n",
    "\n",
    "# Estado Global\n",
    "tracking_objs = {}\n",
    "counts = {cfg[\"id\"]: 0 for cfg in LINES_CFG}\n",
    "counts[\"total\"] = 0\n",
    "counted_ids = {cfg[\"id\"]: set() for cfg in LINES_CFG}\n",
    "next_id = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret: break\n",
    "    \n",
    "    frame = rescale(frame)\n",
    "    curr_t = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
    "    \n",
    "    # 1. Procesamiento de Imagen\n",
    "    mask = bg_subtractor.apply(cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY), learningRate=0.003)\n",
    "    mask[mask == 127] = 0\n",
    "    mask = cv2.medianBlur(mask, 5)\n",
    "    cv2.imshow(\"1. Mascara Cruda (BgSub)\", mask)\n",
    "\n",
    "    # Binarización y morfología\n",
    "    _, bin_img = cv2.threshold(mask, 200, 255, cv2.THRESH_BINARY)\n",
    "    bin_img = cv2.morphologyEx(bin_img, cv2.MORPH_OPEN, KERNEL_ERODE)\n",
    "    bin_img = cv2.morphologyEx(bin_img, cv2.MORPH_CLOSE, KERNEL_CLOSE)\n",
    "    cv2.imshow(\"2. Imagen Binarizada (Final)\", bin_img)\n",
    "\n",
    "    # 2. Tracking por centroides\n",
    "    contours, _ = cv2.findContours(bin_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    curr_objs = {}\n",
    "    \n",
    "    for cnt in contours:\n",
    "        if cv2.contourArea(cnt) < MIN_AREA: continue\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        if w < 10 or h < 10 or not (0.2 < w/h < 5.0): continue\n",
    "        \n",
    "        cx, cy = x + w//2, y + h//2\n",
    "        \n",
    "        c_id, min_d = -1, MAX_DIST\n",
    "        for tid, (tx, ty, thist) in tracking_objs.items():\n",
    "            d = np.hypot(cx - tx, cy - ty)\n",
    "            if d < min_d: min_d, c_id = d, tid\n",
    "            \n",
    "        if c_id == -1: c_id, next_id = next_id, next_id + 1\n",
    "        \n",
    "        hist = tracking_objs[c_id][2] if c_id in tracking_objs else []\n",
    "        hist.append((cx, cy, curr_t))\n",
    "        if len(hist) > 20: hist = hist[-20:]\n",
    "        curr_objs[c_id] = (cx, cy, hist)\n",
    "\n",
    "        kmh = estimate_speed(hist)\n",
    "\n",
    "        # Lógica de cruce de líneas\n",
    "        if len(hist) >= 2:\n",
    "            prev_pt, curr_pt = hist[-2][:2], hist[-1][:2]\n",
    "            for line in LINES_CFG:\n",
    "                lid = line[\"id\"]\n",
    "                if c_id in counted_ids[lid]: continue\n",
    "                dist, t, sign_curr = get_crossing_info(curr_pt, line[\"pts\"][0], line[\"pts\"][1])\n",
    "                _, _, sign_prev = get_crossing_info(prev_pt, line[\"pts\"][0], line[\"pts\"][1])\n",
    "                \n",
    "                if (sign_curr * sign_prev < 0) and (dist < line[\"th\"]) and (line[\"tol\"][0] <= t <= line[\"tol\"][1]):\n",
    "                    counts[lid] += 1\n",
    "                    counts[\"total\"] += 1\n",
    "                    counted_ids[lid].add(c_id)\n",
    "\n",
    "        # Dibujar detección y etiqueta\n",
    "        is_counted = any(c_id in s for s in counted_ids.values())\n",
    "        col = (0, 255, 0) if is_counted else (0, 255, 255)\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), col, 2)\n",
    "        label = f\"ID:{c_id} {int(kmh)}km/h\"\n",
    "        cv2.putText(frame, label, (x, y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, col, 1)\n",
    "\n",
    "    # Actualizar estado del tracker\n",
    "    tracking_objs = curr_objs\n",
    "\n",
    "    # Panel informativo y dibujado de líneas\n",
    "    overlay = frame.copy()\n",
    "    cv2.rectangle(overlay, (10, 10), (320, 60 + len(LINES_CFG)*30), (0, 0, 0), -1)\n",
    "    frame = cv2.addWeighted(overlay, 0.4, frame, 0.6, 0)\n",
    "    \n",
    "    cv2.putText(frame, f\"TOTAL: {counts['total']}\", (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "    for i, line in enumerate(LINES_CFG):\n",
    "        cv2.line(frame, line[\"pts\"][0], line[\"pts\"][1], line[\"col\"], 2)\n",
    "        txt = f\"{line['label']}: {counts[line['id']]}\"\n",
    "        cv2.putText(frame, txt, (20, 80 + i*30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, line[\"col\"], 2)\n",
    "\n",
    "    cv2.imshow(\"3. Traffic Monitor\", frame)\n",
    "    if cv2.waitKey(15) & 0xFF == ord('d'): break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e19fa9",
   "metadata": {},
   "source": [
    "### Código para el segundo vídeo de prueba con la misma estructura y esqueleto pero parámetros cambiados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14dffd1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibrando...\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "def rescale(frame, scale=0.8): \n",
    "    w = int(frame.shape[1] * scale)\n",
    "    h = int(frame.shape[0] * scale)\n",
    "    return cv2.resize(frame, (w, h), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "def point_line_signed_distance(pt, a, b):\n",
    "    return (b[0]-a[0])*(pt[1]-a[1]) - (b[1]-a[1])*(pt[0]-a[0])\n",
    "\n",
    "def point_to_segment_proj_dist(pt, a, b):\n",
    "    pax = pt[0] - a[0]; pay = pt[1] - a[1]\n",
    "    bax = b[0] - a[0]; bay = b[1] - a[1]\n",
    "    denom = bax*bax + bay*bay\n",
    "    if denom == 0: return np.hypot(pax, pay), 0.0\n",
    "    t = (pax*bax + pay*bay) / denom\n",
    "    if t < 0.0: projx, projy = a\n",
    "    elif t > 1.0: projx, projy = b\n",
    "    else: projx, projy = a[0] + t * bax, a[1] + t * bay\n",
    "    return np.hypot(pt[0]-projx, pt[1]-projy), t\n",
    "\n",
    "cap = cv2.VideoCapture('trafico_2.mp4')\n",
    "FPS = cap.get(cv2.CAP_PROP_FPS) or 25\n",
    "\n",
    "object_detector = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=25, detectShadows=True)\n",
    "\n",
    "tracking_objects = {} \n",
    "car_ids_counted = set()\n",
    "vehicle_counts = {\"Total\": 0}\n",
    "left_road_count = 0; right_road_count = 0  \n",
    "direction_counted = defaultdict(set)\n",
    "next_car_id = 0\n",
    "\n",
    "MIN_AREA_BLOB = 250    \n",
    "MAX_DISTANCE = 150     \n",
    "MAX_DISAPPEARED = 10   \n",
    "\n",
    "kernel_close = np.ones((9, 9), np.uint8)  \n",
    "kernel_open = np.ones((3, 3), np.uint8)   \n",
    "kernel_dilate = np.ones((3, 3), np.uint8) \n",
    "\n",
    "PX_TO_KMH_FACTOR = 2.6\n",
    "LINE_V1_P1 = (20, 420); LINE_V1_P2 = (450, 420)\n",
    "LINE_V2_P1 = (600, 420); LINE_V2_P2 = (1050, 420)\n",
    "LINE_DIST_THRESH = 40\n",
    "\n",
    "print(\"Calibrando...\")\n",
    "for _ in range(40):\n",
    "    ret, frame = cap.read()\n",
    "    if not ret: break\n",
    "    frame_s = rescale(frame)\n",
    "    gray = cv2.cvtColor(frame_s, cv2.COLOR_BGR2GRAY)\n",
    "    gray_blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    object_detector.apply(gray_blur)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret: break\n",
    "\n",
    "    frame_s = rescale(frame)\n",
    "    current_time = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
    "    \n",
    "    cv2.imshow(\"1. Video Original\", frame_s)\n",
    "\n",
    "    gray = cv2.cvtColor(frame_s, cv2.COLOR_BGR2GRAY)\n",
    "    gray_blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "    image_mask_raw = object_detector.apply(gray_blur, learningRate=0.001)\n",
    "    \n",
    "    _, image_bin = cv2.threshold(image_mask_raw, 200, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    image_bin = cv2.morphologyEx(image_bin, cv2.MORPH_CLOSE, kernel_close) \n",
    "    image_bin = cv2.morphologyEx(image_bin, cv2.MORPH_OPEN, kernel_open)\n",
    "    image_bin = cv2.dilate(image_bin, kernel_dilate, iterations=1)         \n",
    "    \n",
    "    cv2.imshow(\"2. Mascara Procesada\", image_bin)\n",
    "\n",
    "    contours, _ = cv2.findContours(image_bin, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    img_final = frame_s.copy()\n",
    "    detections = []\n",
    "\n",
    "    cv2.line(img_final, LINE_V1_P1, LINE_V1_P2, (255, 0, 0), 2)\n",
    "    cv2.line(img_final, LINE_V2_P1, LINE_V2_P2, (0, 0, 255), 2)\n",
    "\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if area < MIN_AREA_BLOB: continue\n",
    "        \n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        \n",
    "        if y < 220: continue \n",
    "        \n",
    "        cx, cy = x + w//2, y + h//2\n",
    "        detections.append((cx, cy, x, y, w, h))\n",
    "\n",
    "    if len(tracking_objects) == 0:\n",
    "        for det in detections:\n",
    "            cx, cy, x, y, w, h = det\n",
    "            tracking_objects[next_car_id] = {'center':(cx,cy), 'history':[(cx,cy)], 'disappeared':0, 'box':(x,y,w,h)}\n",
    "            next_car_id += 1\n",
    "    else:\n",
    "        object_ids = list(tracking_objects.keys())\n",
    "        current_centroids = [tracking_objects[obj_id]['center'] for obj_id in object_ids]\n",
    "        \n",
    "        used_rows = set(); used_cols = set()\n",
    "        if len(detections) > 0:\n",
    "            D = np.zeros((len(current_centroids), len(detections)))\n",
    "            for i in range(len(current_centroids)):\n",
    "                for j in range(len(detections)):\n",
    "                    D[i, j] = np.hypot(current_centroids[i][0]-detections[j][0], current_centroids[i][1]-detections[j][1])\n",
    "\n",
    "            rows = D.min(axis=1).argsort(); cols = D.argmin(axis=1)[rows]\n",
    "\n",
    "            for (row, col) in zip(rows, cols):\n",
    "                if row in used_rows or col in used_cols: continue\n",
    "                if D[row, col] > MAX_DISTANCE: continue\n",
    "\n",
    "                obj_id = object_ids[row]\n",
    "                cx, cy, x, y, w, h = detections[col]\n",
    "                \n",
    "                tracking_objects[obj_id]['center'] = (cx, cy)\n",
    "                tracking_objects[obj_id]['box'] = (x, y, w, h)\n",
    "                tracking_objects[obj_id]['disappeared'] = 0\n",
    "                tracking_objects[obj_id]['history'].append((cx, cy))\n",
    "                if len(tracking_objects[obj_id]['history']) > 20: tracking_objects[obj_id]['history'].pop(0)\n",
    "\n",
    "                used_rows.add(row); used_cols.add(col)\n",
    "\n",
    "        for row in range(len(object_ids)):\n",
    "            if row not in used_rows: tracking_objects[object_ids[row]]['disappeared'] += 1\n",
    "        for col in range(len(detections)):\n",
    "            if col not in used_cols:\n",
    "                cx, cy, x, y, w, h = detections[col]\n",
    "                tracking_objects[next_car_id] = {'center':(cx,cy), 'history':[(cx,cy)], 'disappeared':0, 'box':(x,y,w,h)}\n",
    "                next_car_id += 1\n",
    "\n",
    "    tracking_objects = {k: v for k, v in tracking_objects.items() if v['disappeared'] <= MAX_DISAPPEARED}\n",
    "\n",
    "    for car_id, data in tracking_objects.items():\n",
    "        if data['disappeared'] > 0: continue\n",
    "        cx, cy = data['center']; x, y, w, h = data['box']; hist = data['history']\n",
    "\n",
    "        def count_vehicle(direction_key, ref_counter):\n",
    "            if direction_key not in direction_counted[car_id]:\n",
    "                direction_counted[car_id].add(direction_key)\n",
    "                if car_id not in car_ids_counted:\n",
    "                    vehicle_counts[\"Total\"] += 1\n",
    "                    car_ids_counted.add(car_id)\n",
    "                return True\n",
    "            return False\n",
    "\n",
    "        if len(hist) >= 3:\n",
    "            (cx_prev, cy_prev) = hist[-3]\n",
    "            (cx_curr, cy_curr) = hist[-1]\n",
    "            if (point_line_signed_distance((cx_prev, cy_prev), LINE_V1_P1, LINE_V1_P2) * point_line_signed_distance((cx_curr, cy_curr), LINE_V1_P1, LINE_V1_P2) < 0):\n",
    "                d, t = point_to_segment_proj_dist((cx_curr, cy_curr), LINE_V1_P1, LINE_V1_P2)\n",
    "                if d < LINE_DIST_THRESH and 0 <= t <= 1: \n",
    "                    if count_vehicle(\"left_road\", left_road_count): left_road_count += 1\n",
    "            if (point_line_signed_distance((cx_prev, cy_prev), LINE_V2_P1, LINE_V2_P2) * point_line_signed_distance((cx_curr, cy_curr), LINE_V2_P1, LINE_V2_P2) < 0):\n",
    "                d, t = point_to_segment_proj_dist((cx_curr, cy_curr), LINE_V2_P1, LINE_V2_P2)\n",
    "                if d < LINE_DIST_THRESH and 0 <= t <= 1: \n",
    "                    if count_vehicle(\"right_road\", right_road_count): right_road_count += 1\n",
    "\n",
    "        color = (0, 255, 0) if car_id in car_ids_counted else (0, 255, 255)\n",
    "        cv2.rectangle(img_final, (x, y), (x+w, y+h), color, 2)\n",
    "        cv2.putText(img_final, f\"ID:{car_id}\", (x, y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "\n",
    "    # Interfaz\n",
    "    overlay = img_final.copy()\n",
    "    cv2.rectangle(overlay, (0,0), (300,120), (0,0,0), -1)\n",
    "    img_final = cv2.addWeighted(overlay, 0.6, img_final, 0.4, 0)\n",
    "    cv2.putText(img_final, f\"TOTAL: {vehicle_counts['Total']}\", (10,35), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,255,0), 2)\n",
    "    cv2.putText(img_final, f\"Ida: {left_road_count}\", (10,70), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,200,200), 1)\n",
    "    cv2.putText(img_final, f\"Vuelta: {right_road_count}\", (10,100), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (200,200,255), 1)\n",
    "\n",
    "    cv2.imshow(\"3. Monitor de Trafico (Final)\", img_final)\n",
    "\n",
    "    if cv2.waitKey(15) & 0xFF == ord('d'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8c328ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibrando sustractor MOG2...\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "no binding for nonlocal 'vehicle_counts' found (3492517011.py, line 213)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 213\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mnonlocal vehicle_counts, car_ids_counted\u001b[39m\n    ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m no binding for nonlocal 'vehicle_counts' found\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "# --------------------------\n",
    "# CONFIGURACIÓN (ajusta si hace falta)\n",
    "# --------------------------\n",
    "VIDEO_PATH = 'trafico_2.mp4'\n",
    "SCALE = 0.8                # escalado para este vídeo\n",
    "MIN_AREA_BLOB = 180        # area mínima para considerar blob (ajustable)\n",
    "MAX_DISTANCE = 140         # distancia máxima para asociar detecciones a IDs\n",
    "MAX_DISAPPEARED = 10       # frames que un objeto puede desaparecer antes de eliminarse\n",
    "\n",
    "# morfologías (evitan fusionar demasiado los blobs)\n",
    "KERNEL_CLOSE = np.ones((5, 5), np.uint8)\n",
    "KERNEL_OPEN  = np.ones((3, 3), np.uint8)\n",
    "KERNEL_DILATE = np.ones((3, 3), np.uint8)\n",
    "SEPARATION_ERODE = np.ones((3, 3), np.uint8)\n",
    "\n",
    "# líneas de conteo (ajusta puntos según el vídeo)\n",
    "LINE_LEFT_P1  = (20, 420)\n",
    "LINE_LEFT_P2  = (450, 420)\n",
    "LINE_RIGHT_P1 = (600, 420)\n",
    "LINE_RIGHT_P2 = (1050, 420)\n",
    "LINE_DIST_THRESH = 45      # distancia máxima perpendicular a la línea para validar cruce\n",
    "\n",
    "# factor aproximado píxeles->kmh (si quieres mostrar velocidad; opcional)\n",
    "PX_TO_KMH_FACTOR = 2.6\n",
    "\n",
    "# --------------------------\n",
    "# UTILIDADES\n",
    "# --------------------------\n",
    "def rescale(frame, scale=SCALE):\n",
    "    w = int(frame.shape[1] * scale)\n",
    "    h = int(frame.shape[0] * scale)\n",
    "    return cv2.resize(frame, (w, h), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "def signed_point_line(pt, a, b):\n",
    "    # determinante (signo respecto a línea)\n",
    "    return (b[0]-a[0])*(pt[1]-a[1]) - (b[1]-a[1])*(pt[0]-a[0])\n",
    "\n",
    "def point_segment_proj_dist(pt, a, b):\n",
    "    pax = pt[0] - a[0]; pay = pt[1] - a[1]\n",
    "    bax = b[0] - a[0]; bay = b[1] - a[1]\n",
    "    denom = bax*bax + bay*bay\n",
    "    if denom == 0:\n",
    "        return np.hypot(pax, pay), 0.0\n",
    "    t = (pax*bax + pay*bay) / denom\n",
    "    if t < 0.0:\n",
    "        projx, projy = a\n",
    "    elif t > 1.0:\n",
    "        projx, projy = b\n",
    "    else:\n",
    "        projx, projy = a[0] + t * bax, a[1] + t * bay\n",
    "    return np.hypot(pt[0]-projx, pt[1]-projy), t\n",
    "\n",
    "def estimate_speed_px_to_kmh(hist, lookback=6):\n",
    "    if len(hist) < lookback: return 0.0\n",
    "    x1,y1 = hist[-lookback]\n",
    "    x2,y2 = hist[-1]\n",
    "    dist_px = np.hypot(x2-x1, y2-y1)\n",
    "    return dist_px * PX_TO_KMH_FACTOR\n",
    "\n",
    "# --------------------------\n",
    "# INICIALIZACIÓN\n",
    "# --------------------------\n",
    "cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "FPS = cap.get(cv2.CAP_PROP_FPS) or 25\n",
    "\n",
    "# Sustractor MOG2 (parámetros ajustados para este vídeo)\n",
    "object_detector = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=22, detectShadows=True)\n",
    "\n",
    "# Estructuras de tracking / conteo\n",
    "tracking_objects = {}         # id -> {'center':(cx,cy), 'box':(x,y,w,h), 'history':[(cx,cy)...], 'disappeared':n}\n",
    "next_id = 0\n",
    "car_ids_counted = set()       # ids ya contados (para TOTAL y color verde)\n",
    "direction_counted = defaultdict(set)  # para cada id, qué direcciones ya fueron contadas\n",
    "\n",
    "vehicle_counts = {\"Total\": 0}\n",
    "left_road_count = 0\n",
    "right_road_count = 0\n",
    "\n",
    "# parámetros locales\n",
    "print(\"Calibrando sustractor MOG2...\")\n",
    "for _ in range(40):\n",
    "    ret, fr = cap.read()\n",
    "    if not ret: break\n",
    "    fr_s = rescale(fr)\n",
    "    gray = cv2.cvtColor(fr_s, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (5,5), 0)\n",
    "    object_detector.apply(gray, learningRate=0.01)\n",
    "\n",
    "# Regresar al inicio del vídeo (si tu OpenCV lo permite) para procesar desde el principio\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "\n",
    "# --------------------------\n",
    "# BUCLE PRINCIPAL\n",
    "# --------------------------\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_s = rescale(frame)\n",
    "    timestamp = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
    "\n",
    "    # --- PREPROCESADO Y MÁSCARA ---\n",
    "    gray = cv2.cvtColor(frame_s, cv2.COLOR_BGR2GRAY)\n",
    "    gray_blur = cv2.GaussianBlur(gray, (5,5), 0)\n",
    "\n",
    "    mask_raw = object_detector.apply(gray_blur, learningRate=0.002)\n",
    "\n",
    "    # binarizar y morfología (suavizada para no fusionar)\n",
    "    _, mask_bin = cv2.threshold(mask_raw, 200, 255, cv2.THRESH_BINARY)\n",
    "    mask_bin = cv2.morphologyEx(mask_bin, cv2.MORPH_CLOSE, KERNEL_CLOSE)\n",
    "    mask_bin = cv2.morphologyEx(mask_bin, cv2.MORPH_OPEN, KERNEL_OPEN)\n",
    "    # pequeña erosión para separar objetos pegados sin romperlos\n",
    "    mask_bin = cv2.erode(mask_bin, SEPARATION_ERODE, iterations=1)\n",
    "    # una dilatación ligera para devolver tamaño real\n",
    "    mask_bin = cv2.dilate(mask_bin, KERNEL_DILATE, iterations=1) if 'KERNEL_DILATE' in globals() else mask_bin\n",
    "\n",
    "    # visualizar máscaras (útil para debug)\n",
    "    cv2.imshow(\"1. Video Escalado\", frame_s)\n",
    "    cv2.imshow(\"2. Mascara Procesada\", mask_bin)\n",
    "\n",
    "    # --- EXTRACCIÓN DE CONTORNOS (DETECCIONES) ---\n",
    "    contours, _ = cv2.findContours(mask_bin, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    detections = []  # lista de (cx, cy, x, y, w, h)\n",
    "\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if area < MIN_AREA_BLOB: \n",
    "            continue\n",
    "        x,y,w,h = cv2.boundingRect(cnt)\n",
    "        # opcional: filtrar detecciones muy altas en la imagen (p.ej. si quieres ignorar peatones)\n",
    "        # if y < 220: continue\n",
    "        cx, cy = x + w//2, y + h//2\n",
    "        detections.append((cx, cy, x, y, w, h))\n",
    "\n",
    "    # --- ASIGNACIÓN / TRACKING (matching simple por distancia) ---\n",
    "    if len(tracking_objects) == 0:\n",
    "        for det in detections:\n",
    "            cx,cy,x,y,w,h = det\n",
    "            tracking_objects[next_id] = {'center':(cx,cy), 'box':(x,y,w,h), 'history':[(cx,cy,timestamp)], 'disappeared':0}\n",
    "            next_id += 1\n",
    "    else:\n",
    "        object_ids = list(tracking_objects.keys())\n",
    "        object_centroids = [tracking_objects[oid]['center'] for oid in object_ids]\n",
    "\n",
    "        used_rows = set(); used_cols = set()\n",
    "        if len(detections) > 0 and len(object_centroids) > 0:\n",
    "            D = np.zeros((len(object_centroids), len(detections)), dtype=float)\n",
    "            for i in range(len(object_centroids)):\n",
    "                for j in range(len(detections)):\n",
    "                    D[i,j] = np.hypot(object_centroids[i][0] - detections[j][0], object_centroids[i][1] - detections[j][1])\n",
    "\n",
    "            # Greedy matching: filas por la distancia mínima\n",
    "            rows = D.min(axis=1).argsort()\n",
    "            cols = D.argmin(axis=1)[rows]\n",
    "\n",
    "            for (row, col) in zip(rows, cols):\n",
    "                if row in used_rows or col in used_cols:\n",
    "                    continue\n",
    "                if D[row, col] > MAX_DISTANCE:\n",
    "                    continue\n",
    "\n",
    "                oid = object_ids[row]\n",
    "                cx, cy, x, y, w, h = detections[col]\n",
    "\n",
    "                tracking_objects[oid]['center'] = (cx, cy)\n",
    "                tracking_objects[oid]['box'] = (x, y, w, h)\n",
    "                tracking_objects[oid]['disappeared'] = 0\n",
    "                tracking_objects[oid]['history'].append((cx, cy, timestamp))\n",
    "                if len(tracking_objects[oid]['history']) > 30:\n",
    "                    tracking_objects[oid]['history'].pop(0)\n",
    "\n",
    "                used_rows.add(row); used_cols.add(col)\n",
    "\n",
    "        # aumentar desaparecidos para los no asociados y remover detecciones no asociadas (crear nuevos ids)\n",
    "        for row in range(len(object_ids)):\n",
    "            if row not in used_rows:\n",
    "                oid = object_ids[row]\n",
    "                tracking_objects[oid]['disappeared'] += 1\n",
    "\n",
    "        for col in range(len(detections)):\n",
    "            if col not in used_cols:\n",
    "                cx,cy,x,y,w,h = detections[col]\n",
    "                tracking_objects[next_id] = {'center':(cx,cy), 'box':(x,y,w,h), 'history':[(cx,cy,timestamp)], 'disappeared':0}\n",
    "                next_id += 1\n",
    "\n",
    "    # eliminar objetos que han desaparecido demasiado\n",
    "    to_delete = [oid for oid,dd in tracking_objects.items() if dd['disappeared'] > MAX_DISAPPEARED]\n",
    "    for oid in to_delete:\n",
    "        del tracking_objects[oid]\n",
    "\n",
    "    # --- LÓGICA DE CRUCE Y DIBUJADO (amarillo -> verde cuando contado) ---\n",
    "    img_out = frame_s.copy()\n",
    "    # dibujar líneas de conteo\n",
    "    cv2.line(img_out, LINE_LEFT_P1, LINE_LEFT_P2, (255,0,0), 2)\n",
    "    cv2.line(img_out, LINE_RIGHT_P1, LINE_RIGHT_P2, (0,0,255), 2)\n",
    "\n",
    "    for oid, data in list(tracking_objects.items()):\n",
    "        if data['disappeared'] > 0:\n",
    "            # opcional: aún dibujar si desaparecido? aquí lo ignoramos para evitar parpadeos\n",
    "            pass\n",
    "\n",
    "        cx, cy = data['center']\n",
    "        x,y,w,h = data['box']\n",
    "        history = data['history']\n",
    "\n",
    "        # función interna para realizar el conteo por dirección y actualizar contadores\n",
    "        def _count(direction_key):\n",
    "            nonlocal vehicle_counts, car_ids_counted\n",
    "            if direction_key not in direction_counted[oid]:\n",
    "                direction_counted[oid].add(direction_key)\n",
    "                if oid not in car_ids_counted:\n",
    "                    vehicle_counts[\"Total\"] += 1\n",
    "                    car_ids_counted.add(oid)\n",
    "                return True\n",
    "            return False\n",
    "\n",
    "        # comprobación de cruce: se busca cambio de signo entre un punto anterior y el actual\n",
    "        if len(history) >= 3:\n",
    "            prev = history[-3]  # un poco más atrás para mayor robustez\n",
    "            curr = history[-1]\n",
    "            # izquierda\n",
    "            if signed_point_line((prev[0], prev[1]), LINE_LEFT_P1, LINE_LEFT_P2) * signed_point_line((curr[0], curr[1]), LINE_LEFT_P1, LINE_LEFT_P2) < 0:\n",
    "                d, t = point_segment_proj_dist((curr[0], curr[1]), LINE_LEFT_P1, LINE_LEFT_P2)\n",
    "                if d < LINE_DIST_THRESH and 0.0 <= t <= 1.0:\n",
    "                    if _count(\"left_road\"):\n",
    "                        left_road_count += 1\n",
    "            # derecha\n",
    "            if signed_point_line((prev[0], prev[1]), LINE_RIGHT_P1, LINE_RIGHT_P2) * signed_point_line((curr[0], curr[1]), LINE_RIGHT_P1, LINE_RIGHT_P2) < 0:\n",
    "                d, t = point_segment_proj_dist((curr[0], curr[1]), LINE_RIGHT_P1, LINE_RIGHT_P2)\n",
    "                if d < LINE_DIST_THRESH and 0.0 <= t <= 1.0:\n",
    "                    if _count(\"right_road\"):\n",
    "                        right_road_count += 1\n",
    "\n",
    "        # color: amarillo si NO contado, verde si ya contado en TOTAL\n",
    "        color = (0,255,255) if oid not in car_ids_counted else (0,255,0)\n",
    "        cv2.rectangle(img_out, (x,y), (x+w, y+h), color, 2)\n",
    "        cv2.putText(img_out, f\"ID:{oid}\", (x, y-6), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "\n",
    "    # --- PANEL INFORMATIVO ---\n",
    "    overlay = img_out.copy()\n",
    "    cv2.rectangle(overlay, (0,0), (360,130), (0,0,0), -1)\n",
    "    img_out = cv2.addWeighted(overlay, 0.6, img_out, 0.4, 0)\n",
    "    cv2.putText(img_out, f\"TOTAL: {vehicle_counts['Total']}\", (10,30), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,255,0), 2)\n",
    "    cv2.putText(img_out, f\"Ida: {left_road_count}\", (10,65), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,200,200), 1)\n",
    "    cv2.putText(img_out, f\"Vuelta: {right_road_count}\", (10,95), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (200,200,255), 1)\n",
    "\n",
    "    cv2.imshow(\"3. Monitor de Trafico (Final)\", img_out)\n",
    "\n",
    "    # mantener velocidad similar a tu original (waitKey 15)\n",
    "    if cv2.waitKey(15) & 0xFF == ord('d'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
